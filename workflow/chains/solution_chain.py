"""Solution chain for generating detailed answers.

This chain uses a deep thinking model to generate comprehensive
solutions with support for guided and direct tutoring styles.
"""
from typing import Any, Dict
from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.language_models.chat_models import BaseChatModel


SOLUTION_PROMPT = """ä½ æ˜¯ä¸€ä½æ¸©æŸ”çš„å¤§å§å§ï¼Œæ“…é•¿è¾…å¯¼é«˜ä¸‰å­¦ç”Ÿçš„ç”Ÿç‰©å­¦ä¹ ã€‚ç°åœ¨éœ€è¦ç»™å‡ºè¿™é“é¢˜çš„è¯¦ç»†è§£ç­”ã€‚

{persona_prompt}

## é¢˜ç›®
{question}

è¯·ç»™å‡ºè¯¦ç»†çš„è§£ç­”ï¼š
1. é¦–å…ˆåˆ†æé¢˜ç›®è€ƒå¯Ÿçš„çŸ¥è¯†ç‚¹
2. ç»™å‡ºå®Œæ•´çš„è§£é¢˜è¿‡ç¨‹
3. è§£é‡Šæ¯ä¸€æ­¥çš„åŸå› 
4. æ€»ç»“è§£é¢˜æ–¹æ³•å’ŒæŠ€å·§
5. æŒ‡å‡ºå¸¸è§çš„æ˜“é”™ç‚¹

æ³¨æ„ï¼š
- è§£ç­”è¦æ¸…æ™°ã€å®Œæ•´ã€å‡†ç¡®
- å¯ä»¥ç”¨ç”ŸåŠ¨çš„æ¯”å–»å¸®åŠ©ç†è§£
- è¯­æ°”è¦æ¸©æŸ”æœ‰è€å¿ƒ"""


def create_solution_chain(
    deep_model: BaseChatModel,
    persona_prompt: str = ""
) -> RunnableLambda:
    """Create a solution chain for generating detailed answers.
    
    This chain generates a complete solution based solely on the question text.
    User preferences (thinking process, tutoring style) are used in Phase 2
    for personalized tutoring delivery.
    
    Args:
        deep_model: Deep thinking LangChain model
        persona_prompt: AI persona prompt for style
        
    Returns:
        Runnable chain that takes question info and returns solution
    """
    
    async def generate_solution(inputs: Dict[str, Any]) -> str:
        """Generate detailed solution based on question text.
        
        Args:
            inputs: Dict with 'question' (required)
            
        Returns:
            Detailed solution text
        """
        question = inputs.get("question", "")
        
        # Create prompt
        prompt = ChatPromptTemplate.from_template(SOLUTION_PROMPT)
        
        # Create chain
        chain = prompt | deep_model | StrOutputParser()
        
        # Generate solution
        result = await chain.ainvoke({
            "persona_prompt": persona_prompt,
            "question": question
        })
        
        return result
    
    return RunnableLambda(generate_solution)


def format_solution_for_style(solution: str, style: str) -> str:
    """Format solution based on tutoring style.
    
    Args:
        solution: Raw solution text
        style: 'guided' or 'direct'
        
    Returns:
        Formatted solution
    """
    if style == "guided":
        # Add interactive markers for guided style
        lines = solution.split("\n")
        formatted_lines = []
        for line in lines:
            if line.strip().endswith("?") or line.strip().endswith("ï¼Ÿ"):
                # Questions should prompt for user response
                formatted_lines.append(line)
                formatted_lines.append("\nğŸ’­ *è¯·æ€è€ƒä¸€ä¸‹è¿™ä¸ªé—®é¢˜...*\n")
            else:
                formatted_lines.append(line)
        return "\n".join(formatted_lines)
    else:
        return solution
